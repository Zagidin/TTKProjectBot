import os
import pymorphy2
from bot.bot import dp
from pydub import AudioSegment
import speech_recognition as sr
from aiogram.dispatcher import FSMContext
from status_machine.user import UserRegistration
from aiogram.types import Message, ReplyKeyboardRemove, ContentType


my_list_str = {
    "—Ç–∞—Ä–∏—Ñ—ã": {
        "—Ç—Ä–∏–≥–≥–µ—Ä—ã": ["–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π", "–º–æ—â–Ω—ã–π", "—á–µ—Å—Ç–Ω—ã–π", "–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–∞—Ä–∏—Ñ–∞", "—Ç–∞—Ä–∏—Ñ", "—Å–º–µ–Ω–∏—Ç—å —Ç–∞—Ä–∏—Ñ", "—Å–º–µ–Ω–∞ —Ç–∞—Ä–∏—Ñ–∞"],
        "–æ–ø–∏—Å–∞–Ω–∏–µ": "–ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–∞—Ä–∏—Ñ–Ω–æ–≥–æ –ø–ª–∞–Ω–∞."
    },
    "—É—Å–ª—É–≥–∏": {
        "—Ç—Ä–∏–≥–≥–µ—Ä—ã": ["–∞–Ω—Ç–∏–≤–∏—Ä—É—Å", "–∫–∞—Å–ø–µ—Ä—Å–∫–∏–π", "–≤—ã–¥–µ–ª–µ–Ω–Ω—ã–π ip", "ip", "IP", "–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä", "–º–µ–Ω–µ–¥–∂–µ—Ä",
                     "—Ñ–∏—Ä–º–µ–Ω–Ω—ã–π —Ä–æ—É—Ç–µ—Ä", "—Ä–æ—É—Ç–µ—Ä", "–ø–æ–¥–∫–ª—é—á–∏—Ç—å —É—Å–ª—É–≥—É", "—É—Å–ª—É–≥–∞", "–¥–æ–±–∞–≤–∏—Ç—å —É—Å–ª—É–≥—É"],
        "–æ–ø–∏—Å–∞–Ω–∏–µ": "–ó–∞–ø—Ä–æ—Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º —É—Å–ª—É–≥–∞–º."
    },
    "–¥–æ–≥–æ–≤–æ—Ä": {
        "—Ç—Ä–∏–≥–≥–µ—Ä—ã": ["–∑–∞–∫–ª—é—á–∏—Ç—å –¥–æ–≥–æ–≤–æ—Ä", "–æ—Ñ–æ—Ä–º–∏—Ç—å –¥–æ–≥–æ–≤–æ—Ä", "—Ä–∞—Å—Ç–æ—Ä–≥–Ω—É—Ç—å –¥–æ–≥–æ–≤–æ—Ä", "–¥–æ–≥–æ–≤–æ—Ä"],
        "–æ–ø–∏—Å–∞–Ω–∏–µ": "–ó–∞–ø—Ä–æ—Å –Ω–∞ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ, —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ –∏–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–∞."
    }
}

morph = pymorphy2.MorphAnalyzer()

@dp.message_handler(text="–ó–∞–∫–ª—é—á–∏—Ç—å –Ω–æ–≤—ã–π –¥–æ–≥–æ–≤–æ—Ä")
async def registration_user(message: Message):
    await message.answer(
        text="–£–∫–∞–∂–∏—Ç–µ –í–∞—à –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ ‚òé",
        reply_markup=ReplyKeyboardRemove()
    )
    await UserRegistration.phone.set()

@dp.message_handler(state=UserRegistration.phone)
async def user_phone(message: Message, state: FSMContext):
    async with state.proxy() as data:
        data['phone'] = message.text

    await message.reply(
        text="–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ –í–∞—à –∞–¥—Ä–µ—Å, –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —É—Å–ª—É–≥–∏ ‚ú®",
        reply_markup=ReplyKeyboardRemove()
    )
    await UserRegistration.next()

@dp.message_handler(state=UserRegistration.address)
async def user_address(message: Message, state: FSMContext):
    async with state.proxy() as data:
        data['address'] = message.text

    await message.answer(
        text="<b>–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –Ω–∞–º–∏ —Ç–∞—Ä–∏—Ñ—ã –∏ —É—Å–ª—É–≥–∏:\n</b>"
             "\n<b>–°–ø–∏—Å–æ–∫ —Ç–∞—Ä–∏—Ñ–æ–≤:\n</b>"
             "\t–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π - 1000 –ì–±–∏—Ç 800—Ä –≤ –º–µ—Å—è—Ü\n"
             "\t–ú–æ—â–Ω—ã–π - 100 –ú–±–∏—Ç 400—Ä –≤ –º–µ—Å—è—Ü\n"
             "\t–ß–µ—Å—Ç–Ω—ã–π - 10 –ú–±–∏—Ç 100—Ä –≤ –º–µ—Å—è—Ü\n"
             "\n\n<b>–°–ø–∏—Å–æ–∫ —É—Å–ª—É–≥:</b>\n"
             "\t–ê–Ω—Ç–∏–í–∏—Ä—É—Å –ö–∞—Å–ø–µ—Ä—Å–∫–∏–π - 100—Ä –≤ –º–µ—Å—è—Ü\n"
             "\t–í—ã–¥–µ–ª–µ–Ω–Ω—ã–π IP - 100—Ä –≤ –º–µ—Å—è—Ü\n"
             "\t–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - 100—Ä –≤ –º–µ—Å—è—Ü\n"
             "\t–§–∏—Ä–º–µ–Ω–Ω—ã–π —Ä–æ—É—Ç–µ—Ä - 100—Ä –≤ –º–µ—Å—è—Ü\n",
        parse_mode="HTML"
    )

    await message.answer(
        text="–í—ã–±—Ä–∞–≤ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–µ –≤–∞—Å –æ–ø—Ü–∏–∏ –∏–∑ –Ω–∞—à–µ–≥–æ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤."
             "\n–°–æ–æ–±—â–∏—Ç–µ –Ω–∞–º –æ–± —ç—Ç–æ–º —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è..."
    )

    await UserRegistration.next()

@dp.message_handler(content_types=ContentType.VOICE, state=UserRegistration.service)
async def user_provider_service(message: Message, state: FSMContext):
    file_id = message.voice.file_id
    file_info = await dp.bot.get_file(file_id)
    downloaded_file = await dp.bot.download_file(file_info.file_path)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    with open("sound_user/user_gs_start.ogg", "wb") as new_file:
        new_file.write(downloaded_file.getvalue())

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ ffmpeg
    if not os.system("ffmpeg -version >nul 2>nul"):
        recognizer = sr.Recognizer()

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ WAV
        audio = AudioSegment.from_ogg("sound_user/user_gs_start.ogg")
        audio.export("sound_user/user_gs_finish.wav", format="wav")

        with sr.AudioFile("sound_user/user_gs_finish.wav") as source:
            audio_data = recognizer.record(source)
            try:
                text = recognizer.recognize_google(audio_data, language="ru-RU")

                # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
                lemmatized_text = ' '.join([morph.parse(word)[0].normal_form for word in text.split()])

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –∏ –≤—ã–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ
                found_descriptions = []
                for key, value in my_list_str.items():
                    if any(trigger in lemmatized_text for trigger in value["—Ç—Ä–∏–≥–≥–µ—Ä—ã"]):
                        found_descriptions.append(f"{value['–æ–ø–∏—Å–∞–Ω–∏–µ']}")

                if found_descriptions:
                    await message.answer(
                        text="–ü—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ —è –í–∞—Å –ø–æ–Ω—è–ª?\n–°—Ä–µ–¥–∏ –≤–∞—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –µ—Å—Ç—å: "
                    )
                    await message.answer("\t" + "\n".join(found_descriptions))
                else:
                    await message.answer(f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é —è –í–∞—Å –Ω–µ –ø–æ–Ω—è–ª, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ "
                                         f"–∑–∞–ø–∏—Å–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º üòü")
            except sr.UnknownValueError:
                await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.")
            except sr.RequestError as e:
                await message.answer(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞: {e}")
    else:
        await message.answer("FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ FFmpeg.")

    await state.finish()
